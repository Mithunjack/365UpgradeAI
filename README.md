# ğŸš€ Predict student purchase behavior ğŸš€

## ğŸ“– Overview
This project is a **Machine Learning API** built using **FastAPI**, designed to predict whether students will upgrade to a paid plan based on their platform engagement metrics.

The API is **containerized with Docker** and **deployed on Railway** using **GitHub Actions** for CI/CD automation. Additionally, a **Vue.js frontend** has been implemented for seamless interaction with the API.

## ğŸ¯ Features
âœ… **FastAPI for Serving ML Predictions**  
âœ… **Pre-trained ML Model (RandomForestClassifier)**  
âœ… **MLflow for Model Tracking & Versioning**  
âœ… **Dockerized & Deployed on Railway**  
âœ… **Automatic Deployment via GitHub Actions**  
âœ… **Swagger UI for API Testing (`/docs`)**  
âœ… **Vue.js Frontend for User Interaction**

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ .github/workflows/  # GitHub Actions Workflow
â”œâ”€â”€ main.py         # FastAPI application
â”œâ”€â”€ best_model.pkl  # Trained ML model
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ Dockerfile      # Docker Configuration
â”œâ”€â”€ ml-ui/
â”‚   â”œâ”€â”€ src/components/PredictionForm.vue  # Vue.js component
â”‚   â”œâ”€â”€ src/App.vue     # Vue.js main application
â”‚   â”œâ”€â”€ package.json    # Frontend dependencies
â”‚   â”œâ”€â”€ netlify.toml    # Netlify Deployment Config
â”œâ”€â”€ README.md           # Documentation
```

## ğŸ”§ Setup & Installation
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/YOUR_GITHUB_USERNAME/your-repo-name.git
cd your-repo-name
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r backend/requirements.txt
```

### **3ï¸âƒ£ Run FastAPI Locally**
```bash
uvicorn backend.main:app --host 0.0.0.0 --port 8000
```
Now, open **Swagger UI** to test the API:  
ğŸ‘‰ `http://127.0.0.1:8000/docs`

## ğŸ³ Docker Deployment
### **1ï¸âƒ£ Build the Docker Image**
```bash
docker build -t ml-fastapi backend/.
```

### **2ï¸âƒ£ Run the Container**
```bash
docker run -p 8000:8000 ml-fastapi
```
The API will be available at:  
ğŸ‘‰ `http://127.0.0.1:8000/docs`

## ğŸš€ Deployment on Railway
This project is **deployed on Railway**, using **GitHub Actions** to automate deployment.

### **ğŸ”¹ How Deployment Works**
1. **Push Code to GitHub** â†’ GitHub Actions builds Docker image & pushes to Docker Hub.
2. **Railway Pulls & Runs the Container** â†’ New model updates are deployed instantly.
3. **API Becomes Live** â†’ Accessible via Railwayâ€™s public URL.

### **ğŸ”¹ Public API URL**
ğŸ‘‰ `https://365-data-science-production.up.railway.app`

## ğŸ“¡ API Endpoints
### **1ï¸âƒ£ Root Endpoint**
```http
GET /
```
**Response:**
```json
{"message": "FastAPI ML Model is running!"}
```

### **2ï¸âƒ£ Prediction Endpoint**
```http
POST /predict/
```
#### **Request (JSON Format):**
```json
{
    "features": [5.1, 3.5, 1.4, 0.2, 10.5, 8.9, 3.2]
}
```
#### **Response:**
```json
{
    "prediction": 1
}
```

## ğŸ” Using MLflow for Model Tracking
Instead of manually saving `best_model.pkl`, this project uses **MLflow** for model management.

### **1ï¸âƒ£ Save Model to MLflow**
```python
import mlflow
import mlflow.sklearn

mlflow.set_experiment("student_purchase_prediction")

with mlflow.start_run():
    mlflow.sklearn.log_model(rf_clf, "random_forest_model")
```

### **2ï¸âƒ£ Load Model Dynamically in FastAPI**
```python
import mlflow.pyfunc
model = mlflow.pyfunc.load_model("models:/random_forest_model/Production")
```
âœ… This ensures **FastAPI always serves the latest version of the model**.

## ğŸ”¥ CI/CD with GitHub Actions
The project uses **GitHub Actions** for continuous deployment.

### **ğŸ”¹ GitHub Actions Workflow**
1. **On Push to `main` Branch:**
   - Builds a **Docker image**
   - Pushes to **Docker Hub**
   - Deploys to **Railway**

### **ğŸ”¹ Workflow File (`.github/workflows/deploy.yml`)**
```yaml
name: Deploy FastAPI with Docker

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Code
      uses: actions/checkout@v2

    - name: Log in to Docker Hub
      run: echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin

    - name: Build & Push Docker Image
      run: |
        docker build -t YOUR_DOCKER_USERNAME/ml-fastapi:latest backend/.
        docker push YOUR_DOCKER_USERNAME/ml-fastapi:latest

    - name: Deploy to Railway
      run: |
        railway redeploy YOUR_SERVICE_ID
```

## ğŸš€ Frontend Deployment (Vue.js)
The frontend is built with Vue.js and deployed on **Netlify**.

### **ğŸ”¹ Deploy Vue.js on Netlify**
```bash
npm install -g netlify-cli
npm run build
netlify deploy --prod
```
### **ğŸ”¹ Public Frontend URL**
ğŸ‘‰ `https://frolicking-florentine-149b05.netlify.app/`

## ğŸ“Œ Future Improvements
ğŸ”¹ Enhance Vue UI for better user experience  
ğŸ”¹ Add **JWT authentication** for secure access  
ğŸ”¹ Deploy MLflow on Railway for better model management  

## ğŸ’¡ Conclusion
This project demonstrates how to **train, deploy, and automate an ML model using FastAPI, Docker, and Railway**.
With **MLflow integration, automatic deployment, and CI/CD**, the workflow is **fully scalable & production-ready!** ğŸš€


## ğŸ“ License
This project is licensed under the **MIT License** - see the [LICENSE](./LICENSE) file for details.

